{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b61e2e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aryan.ABSALAN\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.01123596 0.01123596 0.01136364 0.01136364 0.01136364]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aryan.ABSALAN\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.011312217194570135\n",
      "Precision: 0.00030881192464321934\n",
      "Recall: 0.011312217194570135\n",
      "F1-Score: 0.000601210588367023\n",
      "Single metric: ['fit_time', 'score_time', 'test_score']\n",
      "Fit time:  [0.0339098  0.03088546 0.02895665]\n",
      "Score time:  [0.00102949 0.00099611 0.00099993]\n",
      "Test score:  [0.01351351 0.02040816 0.02721088]\n",
      "Single metric for data[:150]: ['fit_time', 'score_time', 'test_score']\n",
      "Fit time:  [0.00897408 0.00897241 0.00828862]\n",
      "Score time:  [0. 0. 0.]\n",
      "Test score:  [0.   0.02 0.02]\n",
      "Multiple metric for data[:150]: ['fit_time', 'score_time', 'test_score']\n",
      "[-6984.56 -5156.42 -6063.04]\n",
      "[-0.21701905 -0.070705   -0.06227387]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aryan.ABSALAN\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aryan.ABSALAN\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aryan.ABSALAN\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aryan.ABSALAN\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris, load_diabetes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Accuracy:\n",
    "Accuracy is a general evaluation metric that measures the overall correctness of the predictions.\n",
    "It can be used with any classification algorithm \n",
    "to assess the proportion of correct predictions out of the total predictions.\n",
    "\n",
    "Precision:\n",
    "Precision is a metric that focuses on the quality of positive predictions.\n",
    "It measures the proportion of correctly predicted positive instances \n",
    "out of the total instances predicted as positive.\n",
    "Precision is valuable when the goal is to minimize false positives or \n",
    "when the cost of false positives is high.\n",
    "\n",
    "Recall:\n",
    "Recall, also known as sensitivity or true positive rate,\n",
    "measures the ability of a model to identify positive instances.\n",
    "It represents the proportion of correctly predicted positive instances \n",
    "out of the total actual positive instances.\n",
    "Recall is particularly useful when the goal is to minimize false negatives or \n",
    "when the cost of false negatives is high.\n",
    "\n",
    "F1-score:\n",
    "The F1-score is a combined metric that balances both precision and recall.\n",
    "It provides a single value that takes into account both metrics and \n",
    "is useful when there is a trade-off between precision and recall.\n",
    "The F1-score is the harmonic mean of precision and recall and is calculated as \n",
    "2 * (precision * recall) / (precision + recall).\n",
    "\"\"\"\n",
    "\n",
    "# # Load the iris dataset\n",
    "# iris = load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes_dataset = load_diabetes()\n",
    "X = diabetes_dataset.data\n",
    "y = diabetes_dataset.target\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Perform cross-validation and obtain evaluation scores\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the evaluation scores for each fold\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "\n",
    "# Perform cross-validation and obtain predicted values\n",
    "predicted_values = cross_val_predict(model, X, y, cv=5)\n",
    "\n",
    "# Compute accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(y, predicted_values)\n",
    "precision = precision_score(y, predicted_values, average='weighted')\n",
    "recall = recall_score(y, predicted_values, average='weighted')\n",
    "f1 = f1_score(y, predicted_values, average='weighted')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "\n",
    "# Evaluate metric(s) by cross-validation and also record fit/score times.\n",
    "\n",
    "# Single metric evaluation using cross_validate\n",
    "cv_results = cross_validate(model, X, y, cv=3)\n",
    "\n",
    "print(\"Single metric:\", sorted(cv_results.keys()))\n",
    "\n",
    "print(\"Fit time: \",cv_results['fit_time'])\n",
    "print(\"Score time: \",cv_results['score_time'])\n",
    "print(\"Test score: \",cv_results['test_score'])\n",
    "\n",
    "X = diabetes_dataset.data[:150]\n",
    "y = diabetes_dataset.target[:150]\n",
    "\n",
    "# Single metric evaluation using cross_validate for data[:150]\n",
    "cv_results = cross_validate(model, X, y, cv=3)\n",
    "\n",
    "print(\"Single metric for data[:150]:\", sorted(cv_results.keys()))\n",
    "\n",
    "print(\"Fit time: \",cv_results['fit_time'])\n",
    "print(\"Score time: \",cv_results['score_time'])\n",
    "print(\"Test score: \",cv_results['test_score'])\n",
    "\n",
    "# Multiple metric evaluation using cross_validate\n",
    "\n",
    "scores = cross_validate(model, X, y, cv=3,scoring=('r2', 'neg_mean_squared_error'),return_train_score=True)\n",
    "\n",
    "print(\"Multiple metric for data[:150]:\", sorted(cv_results.keys()))\n",
    "\n",
    "print(scores['test_neg_mean_squared_error'])\n",
    "print(scores['train_r2'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
